# ğŸ¥ FitPulse - Milestone 1: Data Preprocessing Pipeline

## ğŸ“‹ Overview

Milestone 1 provides a comprehensive data preprocessing pipeline for health and fitness data. It handles multiple file formats, performs intelligent validation, and creates clean, aligned datasets ready for analysis.

## âœ¨ Features

### ğŸ”µ Data Loading & Format Support
- **Multi-format support**: CSV, JSON, Excel, Parquet
- **Intelligent type detection**: Automatic data type identification
- **Schema validation**: Ensures data integrity
- **Error handling**: Graceful handling of malformed data

### ğŸ” Advanced Data Validation
- **Quality scoring**: 0-100 quality assessment
- **Outlier detection**: Statistical outlier identification using IQR and Z-score
- **Missing value handling**: Smart imputation strategies
- **Range validation**: Physiological range checks for health metrics
- **Duplicate removal**: Timestamp-based deduplication

### â° Time Series Alignment
- **Smart resampling**: Data-type aware aggregation
- **Gap filling**: Multiple interpolation methods
- **Frequency detection**: Automatic time frequency identification
- **Timezone handling**: Multi-timezone support with automatic detection

### ğŸ“Š Data Quality Reporting
- **Comprehensive metrics**: Completeness, accuracy, consistency scores
- **Visual dashboards**: Interactive quality visualizations
- **Export capabilities**: JSON reports with detailed statistics

## ğŸš€ Quick Start

### Installation
```bash
pip install streamlit pandas numpy plotly scipy pytz scikit-learn
```

### Launch Application
```bash
streamlit run app.py
```

### Usage Steps
1. **Upload Data**: Drag & drop files or use sample data
2. **Configure Settings**: Set target frequency and fill method
3. **Run Pipeline**: Click "ğŸš€ Run Complete Pipeline"
4. **Review Results**: Examine quality reports and visualizations
5. **Export Data**: Download processed datasets and reports

## ğŸ“ Supported Data Types

### Heart Rate Data
- **Columns**: `timestamp`, `heart_rate`
- **Range**: 40-200 BPM
- **Validation**: Physiological range checks

### Steps Data
- **Columns**: `timestamp`, `step_count`
- **Range**: 0-50,000 steps/day
- **Aggregation**: Sum for resampling

### Sleep Data
- **Columns**: `timestamp`, `duration_minutes`
- **Range**: 0-24 hours
- **Validation**: Sleep duration checks

## ğŸ”§ Configuration Options

### Target Frequency
- `1min`: Minute-level data
- `5min`: 5-minute intervals
- `15min`: Quarter-hour intervals
- `1H`: Hourly data
- `1D`: Daily aggregation

### Fill Methods
- **Interpolate**: Linear interpolation for gaps
- **Forward Fill**: Use last valid value
- **Backward Fill**: Use next valid value
- **Mean**: Fill with column mean

## ğŸ“Š Output Features

### Processed Datasets
- Clean, validated data
- Uniform timestamps
- Consistent formatting
- Quality metadata

### Quality Reports
- Data completeness scores
- Outlier statistics
- Processing summaries
- Validation results

### Visualizations
- Time series plots
- Quality dashboards
- Distribution charts
- Correlation matrices

## ğŸ¯ Quality Metrics

### Completeness Score
- Percentage of non-missing values
- Time coverage assessment
- Data density evaluation

### Accuracy Score
- Range validation results
- Outlier detection metrics
- Type consistency checks

### Consistency Score
- Timestamp regularity
- Value distribution analysis
- Pattern consistency

## ğŸ” Advanced Features

### Timezone Processing
- Automatic timezone detection
- DST transition handling
- Multi-timezone normalization
- UTC conversion

### Smart Validation
- Physiological range checks
- Statistical outlier detection
- Missing value pattern analysis
- Duplicate identification

### Export Options
- CSV format with metadata
- JSON reports with statistics
- Processing logs
- Quality assessments

## ğŸ“ˆ Performance

- **Processing Speed**: ~1000 rows/second
- **Memory Efficient**: Streaming processing for large files
- **Scalable**: Handles datasets up to 1M+ rows
- **Real-time Feedback**: Progress indicators and status updates

## ğŸ› ï¸ Technical Details

### Core Classes
- `DataLoader`: Multi-format file loading
- `DataValidator`: Quality validation and cleaning
- `TimeAligner`: Time series alignment and resampling
- `PreprocessingPipeline`: Main orchestrator

### Dependencies
- `pandas`: Data manipulation
- `numpy`: Numerical operations
- `plotly`: Interactive visualizations
- `streamlit`: Web interface

## ğŸ“ Support

For issues or questions about Milestone 1:
1. Check the quality reports for data issues
2. Review validation messages in the UI
3. Ensure data follows expected format
4. Verify file encoding and structure

---

**Ready for Milestone 2?** Once your data is preprocessed, proceed to advanced ML features including feature extraction, forecasting, and clustering analysis.